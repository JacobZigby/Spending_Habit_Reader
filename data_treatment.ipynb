{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports here\n",
    "\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is where the fun begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initalize all values here:\n",
    "#capitals as per naming convention for python when you want to assign a constant\n",
    "#padding needed to not read repetative noise\n",
    "OFFSET = 6\n",
    "#height in pixels of each row\n",
    "HEIGHT = 27\n",
    "#config for the ocr config arg\n",
    "CONFIG = \"--psm 12 --oem 1\"\n",
    "#collect the year for the files later by regular expression but for the time being, since we already know that the numbers are in the range of 0-9 position, we'll just slice\n",
    "\n",
    "#set up paths\n",
    "SOURCE_PATH = \"data/unprocessed/debit/\"\n",
    "SAVE_PATH = \"data/processed/debit/\"\n",
    "#-1 to remove the \"/\"\n",
    "file_names = os.listdir(SOURCE_PATH[:-1])\n",
    "for file in file_names:\n",
    "    #create vars to hold each column (we will zip em together later to turn into a dataframe)\n",
    "    #also reset values\n",
    "    date = []\n",
    "    description = []\n",
    "    charge =[]\n",
    "    total = []\n",
    "\n",
    "    #here we will assume that the pdf size is 1700 to 2200 (later we will return to add more adaptability)\n",
    "    #set up base crop dimensision\n",
    "    left = 325\n",
    "    top = 397\n",
    "    right = 1650\n",
    "    #bottom will be under constant change per loop, so we'll just initalize it\n",
    "    bottom = top + HEIGHT\n",
    "\n",
    "    #come back later to allow for more than one page to be processed\n",
    "    image = convert_from_path(SOURCE_PATH + file)[1]\n",
    "\n",
    "    #make shift do-while loop\n",
    "    #we shall read all the way to the bottom, cleaning will be done in the next steps\n",
    "    #we could switch it for a forloop sure by dividing the remainging length by the total rows height and just seeing how many times we can run it, but I already wrote this\n",
    "    while bottom <= 2200:\n",
    "        #Crop the image to just read row by row\n",
    "        seg = image.crop((left, top, right, bottom))\n",
    "\n",
    "        #Lets OCR this thing\n",
    "        info = pytesseract.image_to_string(seg, config=CONFIG)\n",
    "        print(info, file_name)\n",
    "        info = info.rstrip(\"\\n\")\n",
    "        info = info.split(\"\\n\\n\")\n",
    "\n",
    "        #some in precosion error handeling\n",
    "        if len(info) > 3:\n",
    "            date.append(info[0])\n",
    "            description.append(info[1])\n",
    "            charge.append(info[2])\n",
    "            total.append(info[3])\n",
    "\n",
    "        #reset the crop values\n",
    "        top = bottom + OFFSET\n",
    "        bottom = top + HEIGHT\n",
    "    \n",
    "    #turn into a df\n",
    "    file_name = file[:10]\n",
    "    df = pd.DataFrame(list(zip(date, description, charge, total)), columns=[\"date\", \"description\", \"charge\", \"total\"])\n",
    "    #index set to false as it is not needed\n",
    "    df.to_csv(SAVE_PATH + file_name + \".csv\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To note over five years of data, only three anomolies showed up and two pages where a second page was given to store more transaction information <br>\n",
    "solution for anomoly: all three had the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we clean the data in all the csvs\n",
    "\n",
    "#Step one get rid of columns we can't use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to time restraints I had to fix some files by hand so that the values I'd use for the model would be at their most accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we merge all csv's into one big"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31668c276e2b8e47189cd17d89a548db85eb18b031d19ae00671844f6622a6b2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('habit_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
